{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17cc69a",
   "metadata": {},
   "source": [
    "## PyTorch 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ca505f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:22:11.100711Z",
     "start_time": "2023-10-14T07:22:00.960064Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4de938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x176dbb6d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b24f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:35:38.887677Z",
     "start_time": "2023-10-14T07:35:37.968802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  const  \n",
       "501     21.0  391.99   9.67    1.0  \n",
       "502     21.0  396.90   9.08    1.0  \n",
       "503     21.0  396.90   5.64    1.0  \n",
       "504     21.0  393.45   6.48    1.0  \n",
       "505     21.0  396.90   7.88    1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "#columns = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "df = pd.DataFrame(data,columns=columns)\n",
    "#df['PRICE'] = target\n",
    "df['const'] = np.ones(df.shape[0])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1af429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  const  \n",
       "501     21.0  391.99   9.67    1.0  \n",
       "502     21.0  396.90   9.08    1.0  \n",
       "503     21.0  396.90   5.64    1.0  \n",
       "504     21.0  393.45   6.48    1.0  \n",
       "505     21.0  396.90   7.88    1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 저작권 이슈로 사용이 불가하다고 한다. ㅠㅠ\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['const'] = np.ones(df.shape[0])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5faef",
   "metadata": {},
   "source": [
    "#### 수학적 방식 OLS???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b95fdb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:35:41.200993Z",
     "start_time": "2023-10-14T07:35:41.180995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = df.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d57e2632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:35:41.704089Z",
     "start_time": "2023-10-14T07:35:41.694090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([506, 14]), torch.Size([506, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(df.values)\n",
    "y = torch.tensor(target).view(-1, 1)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2edb960d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:35:42.602977Z",
     "start_time": "2023-10-14T07:35:42.591973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 506])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XT = torch.transpose(x, 0, 1)\n",
    "XT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbc603f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:35:44.874768Z",
     "start_time": "2023-10-14T07:35:44.856752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 집값 : tensor([18.4061], dtype=torch.float64) 실제 집값 : 18.2\n",
      "예측한 집값 : tensor([18.9995], dtype=torch.float64) 실제 집값 : 15.0\n"
     ]
    }
   ],
   "source": [
    "w = torch.matmul(torch.matmul(torch.inverse(torch.matmul(XT, x)), XT), y)\n",
    "y_pred = torch.matmul(x, w)\n",
    "\n",
    "print(\"예측한 집값 :\", y_pred[19], \"실제 집값 :\", target[19])\n",
    "print(\"예측한 집값 :\", y_pred[10], \"실제 집값 :\", target[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829253c",
   "metadata": {},
   "source": [
    "#### Gradient descent 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c692d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:37:08.728531Z",
     "start_time": "2023-10-14T07:37:08.708508Z"
    }
   },
   "outputs": [],
   "source": [
    "w = torch.rand((14, 1), dtype=torch.float64, requires_grad=True)\n",
    "b = torch.rand((1, 1),  dtype=torch.float64, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f0de699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:37:26.661541Z",
     "start_time": "2023-10-14T07:37:26.634719Z"
    }
   },
   "outputs": [],
   "source": [
    "z = x.matmul(w) + b\n",
    "loss = torch.mean((z - y)**2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7504aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:37:30.290908Z",
     "start_time": "2023-10-14T07:37:30.276820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d309563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:37:33.735467Z",
     "start_time": "2023-10-14T07:37:32.805543Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdfbe4fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:37:34.467699Z",
     "start_time": "2023-10-14T07:37:34.448054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.2991e+03],\n",
       "         [6.7920e+03],\n",
       "         [1.0170e+04],\n",
       "         [5.1937e+01],\n",
       "         [4.5796e+02],\n",
       "         [4.8648e+03],\n",
       "         [5.8423e+04],\n",
       "         [2.6462e+03],\n",
       "         [9.6833e+03],\n",
       "         [3.6684e+05],\n",
       "         [1.4768e+04],\n",
       "         [2.6972e+05],\n",
       "         [1.1155e+04],\n",
       "         [7.8464e+02]], dtype=torch.float64),\n",
       " tensor([[784.6375]], dtype=torch.float64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9469b361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:37:42.917623Z",
     "start_time": "2023-10-14T07:37:42.898624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(173420.1276, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "406bc69e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:39:41.857442Z",
     "start_time": "2023-10-14T07:39:41.804383Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# requires_grad = True 일경우 numpy 호출이 불가능\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# requires_grad = True 일경우 numpy 호출이 불가능\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d88c8",
   "metadata": {},
   "source": [
    "requires_grad를 없애고 값을 불러와야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e311c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:39:08.474495Z",
     "start_time": "2023-10-14T07:39:08.462470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(173420.12761429)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.detach().numpy() # 값 value만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e58f5007",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:39:09.419349Z",
     "start_time": "2023-10-14T07:39:09.405350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173420.12761428562\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # 값 value만 가져오기\n",
    "    print(loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da55bf",
   "metadata": {},
   "source": [
    "pytorch에서 그냥 item으로 바로 값을 추출 가능하다...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd78c4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:40:22.138111Z",
     "start_time": "2023-10-14T07:40:22.121058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173420.12761428562"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df6bf3",
   "metadata": {},
   "source": [
    "#### 1. backward()로 학습\n",
    "#### assign 대신에 data에 접근해서 값을 수정 \n",
    "\n",
    "tensor.data = 다른데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0435d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:44:46.269826Z",
     "start_time": "2023-10-14T07:44:46.213682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 - loss : 173420.12761428562\r",
      "  1 - loss : 1282537.835507659\r",
      "  2 - loss : 988940.9189275338\r",
      "  3 - loss : 762572.3852158815\r",
      "  4 - loss : 588037.4176980414\r",
      "  5 - loss : 453466.6792211262\r",
      "  6 - loss : 349708.9158745924\r",
      "  7 - loss : 269708.4806353891\r",
      "  8 - loss : 208025.421113721\r",
      "  9 - loss : 160465.4779858939\r",
      " 10 - loss : 123794.82037201486\r",
      " 11 - loss : 95520.11061565607\r",
      " 12 - loss : 73718.93622062668\r",
      " 13 - loss : 56909.07371519256\r",
      " 14 - loss : 43947.69122696469\r",
      " 15 - loss : 33953.6333940604\r",
      " 16 - loss : 26247.50254076979\r",
      " 17 - loss : 20305.46067918458\r",
      " 18 - loss : 15723.610249198327\r",
      " 19 - loss : 12190.53109144229\r",
      " 20 - loss : 9466.105925030002\r",
      " 21 - loss : 7365.194322188442\r",
      " 22 - loss : 5745.044936047703\r",
      " 23 - loss : 4495.589981310517\r",
      " 24 - loss : 3531.9619866639027\r",
      " 25 - loss : 2788.7239673908657\r",
      " 26 - loss : 2215.420687262181\r",
      " 27 - loss : 1773.1485164013418\r",
      " 28 - loss : 1431.910657106677\r",
      " 29 - loss : 1168.577913773651\r",
      " 30 - loss : 965.3163583228538\r",
      " 31 - loss : 808.3749893035043\r",
      " 32 - loss : 687.150960185815\r",
      " 33 - loss : 593.4688249124988\r",
      " 34 - loss : 521.024799978818\r",
      " 35 - loss : 464.9582616770912\r",
      " 36 - loss : 421.5213476041572\r",
      " 37 - loss : 387.82420131347635\r",
      " 38 - loss : 361.6385416252781\r",
      " 39 - loss : 341.2462032653248\r",
      " 40 - loss : 325.32235279260397\r",
      " 41 - loss : 312.845441071412\r",
      " 42 - loss : 303.02777111868\r",
      " 43 - loss : 295.2619615892321\r",
      " 44 - loss : 289.07966673075634\r",
      " 45 - loss : 284.11974681116055\r",
      " 46 - loss : 280.1037254372998\r",
      " 47 - loss : 276.8168655201232\r",
      " 48 - loss : 274.09357757164486\r",
      " 49 - loss : 271.8061685082488\r",
      " 50 - loss : 269.8561662023981\r",
      " 51 - loss : 268.1676301068875\r",
      " 52 - loss : 266.6819932743027\r",
      " 53 - loss : 265.3540851862639\r",
      " 54 - loss : 264.14906506824514\r",
      " 55 - loss : 263.0400572521237\r",
      " 56 - loss : 262.00632786691403\r",
      " 57 - loss : 261.0318789319997\r",
      " 58 - loss : 260.10436429764854\r",
      " 59 - loss : 259.21425375309343\r",
      " 60 - loss : 258.35418848994203\r",
      " 61 - loss : 257.51848411464675\r",
      " 62 - loss : 256.70274743226076\r",
      " 63 - loss : 255.9035809563732\r",
      " 64 - loss : 255.11835506254474\r",
      " 65 - loss : 254.34503230001874\r",
      " 66 - loss : 253.5820319214543\r",
      " 67 - loss : 252.8281254238474\r",
      " 68 - loss : 252.08235600148586\r",
      " 69 - loss : 251.34397643694314\r",
      " 70 - loss : 250.61240120925174\r",
      " 71 - loss : 249.8871695646436\r",
      " 72 - loss : 249.16791704030297\r",
      " 73 - loss : 248.45435350606832\r",
      " 74 - loss : 247.7462462320015\r",
      " 75 - loss : 247.0434068313078\r",
      " 76 - loss : 246.3456811914712\r",
      " 77 - loss : 245.65294170955124\r",
      " 78 - loss : 244.96508130418366\r",
      " 79 - loss : 244.28200879756858\r",
      " 80 - loss : 243.60364535384153\r",
      " 81 - loss : 242.92992173200614\r",
      " 82 - loss : 242.26077616696932\r",
      " 83 - loss : 241.59615273490292\r",
      " 84 - loss : 240.93600009206637\r",
      " 85 - loss : 240.28027050160802\r",
      " 86 - loss : 239.62891908242614\r",
      " 87 - loss : 238.98190322926638\r",
      " 88 - loss : 238.33918216486128\r",
      " 89 - loss : 237.70071659389362\r",
      " 90 - loss : 237.06646843548006\r",
      " 91 - loss : 236.4364006162081\r",
      " 92 - loss : 235.81047690987202\r",
      " 93 - loss : 235.18866181322164\r",
      " 94 - loss : 234.57092044948976\r",
      " 95 - loss : 233.95721849334362\r",
      " 96 - loss : 233.34752211236375\r",
      " 97 - loss : 232.74179792127185\r",
      " 98 - loss : 232.14001294599692\r",
      " 99 - loss : 231.54213459533327\r"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.000003 # 3e-7\n",
    "\n",
    "for epoch in range(100):\n",
    "    # 위에 데이터프레임에 const = 1로 상수값을 줘서 사실 b는 필요가없다.\n",
    "    # 강의 내용상 b를 포함해서 진행\n",
    "    z = x.matmul(w) + b\n",
    "    loss = torch.mean((y - z)**2)  \n",
    "    \n",
    "    # 미분 계산\n",
    "    loss.backward()\n",
    "    \n",
    "    # 가중치 업데이트\n",
    "    w.data -= learning_rate * w.grad\n",
    "    b.data -= learning_rate * b.grad\n",
    "    \n",
    "    # 진행상황 출력\n",
    "    print(\"{:3} - loss : {}\".format(epoch, loss.item()), end=\"\\r\")\n",
    "    \n",
    "    # w.grad의 grad는 누적해서 구하게 된다. \n",
    "    # 그래서 epoch가 끝나면 초기화를 해줘야한다.\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1784e5",
   "metadata": {},
   "source": [
    "#### 2. torch.autograd.grad 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa14f491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:51:44.333295Z",
     "start_time": "2023-10-14T07:51:44.288165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 - loss : 230.94813063845805\r",
      "  1 - loss : 230.3579691869743\r",
      "  2 - loss : 229.77161868044817\r",
      "  3 - loss : 229.18904787464788\r",
      "  4 - loss : 228.61022583187074\r",
      "  5 - loss : 228.03512191288704\r",
      "  6 - loss : 227.46370577013525\r",
      "  7 - loss : 226.89594734188992\r",
      "  8 - loss : 226.33181684718264\r",
      "  9 - loss : 225.77128478131144\r",
      " 10 - loss : 225.2143219118094\r",
      " 11 - loss : 224.66089927477068\r",
      " 12 - loss : 224.11098817146103\r",
      " 13 - loss : 223.5645601651499\r",
      " 14 - loss : 223.02158707812137\r",
      " 15 - loss : 222.48204098882596\r",
      " 16 - loss : 221.94589422914873\r",
      " 17 - loss : 221.41311938177\r",
      " 18 - loss : 220.88368927760447\r",
      " 19 - loss : 220.35757699330446\r",
      " 20 - loss : 219.83475584881924\r",
      " 21 - loss : 219.3151994050008\r",
      " 22 - loss : 218.79888146125208\r",
      " 23 - loss : 218.2857760532117\r",
      " 24 - loss : 217.77585745047216\r",
      " 25 - loss : 217.26910015432895\r",
      " 26 - loss : 216.76547889555752\r",
      " 27 - loss : 216.26496863221755\r",
      " 28 - loss : 215.76754454748118\r",
      " 29 - loss : 215.273182047487\r",
      " 30 - loss : 214.78185675921557\r",
      " 31 - loss : 214.29354452838842\r",
      " 32 - loss : 213.80822141738852\r",
      " 33 - loss : 213.32586370320155\r",
      " 34 - loss : 212.84644787537857\r",
      " 35 - loss : 212.36995063401903\r",
      " 36 - loss : 211.8963488877735\r",
      " 37 - loss : 211.42561975186624\r",
      " 38 - loss : 210.9577405461379\r",
      " 39 - loss : 210.492688793106\r",
      " 40 - loss : 210.03044221604614\r",
      " 41 - loss : 209.57097873709105\r",
      " 42 - loss : 209.1142764753476\r",
      " 43 - loss : 208.6603137450336\r",
      " 44 - loss : 208.2090690536316\r",
      " 45 - loss : 207.76052110006083\r",
      " 46 - loss : 207.31464877286774\r",
      " 47 - loss : 206.87143114843263\r",
      " 48 - loss : 206.43084748919537\r",
      " 49 - loss : 205.9928772418966\r",
      " 50 - loss : 205.55750003583788\r",
      " 51 - loss : 205.1246956811569\r",
      " 52 - loss : 204.69444416712074\r",
      " 53 - loss : 204.26672566043487\r",
      " 54 - loss : 203.84152050356934\r",
      " 55 - loss : 203.41880921310005\r",
      " 56 - loss : 202.99857247806742\r",
      " 57 - loss : 202.58079115834994\r",
      " 58 - loss : 202.16544628305377\r",
      " 59 - loss : 201.7525190489184\r",
      " 60 - loss : 201.34199081873717\r",
      " 61 - loss : 200.93384311979293\r",
      " 62 - loss : 200.52805764230982\r",
      " 63 - loss : 200.12461623791918\r",
      " 64 - loss : 199.72350091814045\r",
      " 65 - loss : 199.32469385287678\r",
      " 66 - loss : 198.92817736892587\r",
      " 67 - loss : 198.53393394850409\r",
      " 68 - loss : 198.14194622778558\r",
      " 69 - loss : 197.75219699545553\r",
      " 70 - loss : 197.36466919127713\r",
      " 71 - loss : 196.9793459046727\r",
      " 72 - loss : 196.5962103733181\r",
      " 73 - loss : 196.21524598175125\r",
      " 74 - loss : 195.836436259994\r",
      " 75 - loss : 195.4597648821867\r",
      " 76 - loss : 195.08521566523706\r",
      " 77 - loss : 194.71277256748084\r",
      " 78 - loss : 194.3424196873569\r",
      " 79 - loss : 193.9741412620935\r",
      " 80 - loss : 193.60792166640869\r",
      " 81 - loss : 193.24374541122216\r",
      " 82 - loss : 192.88159714238046\r",
      " 83 - loss : 192.5214616393937\r",
      " 84 - loss : 192.16332381418505\r",
      " 85 - loss : 191.80716870985205\r",
      " 86 - loss : 191.4529814994401\r",
      " 87 - loss : 191.1007474847272\r",
      " 88 - loss : 190.75045209502144\r",
      " 89 - loss : 190.40208088596896\r",
      " 90 - loss : 190.0556195383744\r",
      " 91 - loss : 189.71105385703186\r",
      " 92 - loss : 189.36836976956806\r",
      " 93 - loss : 189.02755332529577\r",
      " 94 - loss : 188.688590694079\r",
      " 95 - loss : 188.35146816520862\r",
      " 96 - loss : 188.01617214628905\r",
      " 97 - loss : 187.68268916213592\r",
      " 98 - loss : 187.35100585368372\r",
      " 99 - loss : 187.02110897690494\r"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.000003\n",
    "\n",
    "for epoch in range(100):    \n",
    "    z = (x.matmul(w) + b)\n",
    "    loss = torch.mean((z - y)**2)  \n",
    "    \n",
    "    grads = torch.autograd.grad(loss, [w, b])\n",
    "    \n",
    "    w.data -= grads[0] * learning_rate\n",
    "    b.data -= grads[1] * learning_rate\n",
    "\n",
    "    print(\"{:3} - loss : {}\".format(epoch, loss.item()), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbba60f",
   "metadata": {},
   "source": [
    "#### 3. optimizer 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acf3c178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:53:51.521241Z",
     "start_time": "2023-10-14T07:53:51.501253Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD([w, b], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76d26f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:53:52.592571Z",
     "start_time": "2023-10-14T07:53:52.533342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 - loss : 186.69298540173847\r",
      "  1 - loss : 186.36662211102913\r",
      "  2 - loss : 186.04200619947747\r",
      "  3 - loss : 185.71912487259905\r",
      "  4 - loss : 185.3979654456944\r",
      "  5 - loss : 185.07851534282818\r",
      "  6 - loss : 184.76076209581947\r",
      "  7 - loss : 184.4446933432398\r",
      "  8 - loss : 184.130296829423\r",
      "  9 - loss : 183.8175604034827\r",
      " 10 - loss : 183.50647201834073\r",
      " 11 - loss : 183.19701972976384\r",
      " 12 - loss : 182.8891916954104\r",
      " 13 - loss : 182.5829761738857\r",
      " 14 - loss : 182.27836152380686\r",
      " 15 - loss : 181.9753362028763\r",
      " 16 - loss : 181.67388876696467\r",
      " 17 - loss : 181.37400786920148\r",
      " 18 - loss : 181.07568225907605\r",
      " 19 - loss : 180.7789007815458\r",
      " 20 - loss : 180.4836523761537\r",
      " 21 - loss : 180.18992607615417\r",
      " 22 - loss : 179.89771100764705\r",
      " 23 - loss : 179.60699638872055\r",
      " 24 - loss : 179.31777152860153\r",
      " 25 - loss : 179.0300258268147\r",
      " 26 - loss : 178.74374877234953\r",
      " 27 - loss : 178.45892994283562\r",
      " 28 - loss : 178.17555900372474\r",
      " 29 - loss : 177.89362570748247\r",
      " 30 - loss : 177.61311989278624\r",
      " 31 - loss : 177.3340314837316\r",
      " 32 - loss : 177.05635048904622\r",
      " 33 - loss : 176.78006700131095\r",
      " 34 - loss : 176.505171196189\r",
      " 35 - loss : 176.2316533316618\r",
      " 36 - loss : 175.95950374727283\r",
      " 37 - loss : 175.68871286337807\r",
      " 38 - loss : 175.41927118040456\r",
      " 39 - loss : 175.15116927811476\r",
      " 40 - loss : 174.88439781487907\r",
      " 41 - loss : 174.6189475269549\r",
      " 42 - loss : 174.35480922777268\r",
      " 43 - loss : 174.0919738072285\r",
      " 44 - loss : 173.83043223098377\r",
      " 45 - loss : 173.57017553977172\r",
      " 46 - loss : 173.3111948487101\r",
      " 47 - loss : 173.05348134662069\r",
      " 48 - loss : 172.79702629535552\r",
      " 49 - loss : 172.54182102912912\r",
      " 50 - loss : 172.28785695385758\r",
      " 51 - loss : 172.0351255465035\r",
      " 52 - loss : 171.78361835442746\r",
      " 53 - loss : 171.53332699474564\r",
      " 54 - loss : 171.2842431536939\r",
      " 55 - loss : 171.03635858599705\r",
      " 56 - loss : 170.78966511424514\r",
      " 57 - loss : 170.54415462827515\r",
      " 58 - loss : 170.2998190845587\r",
      " 59 - loss : 170.05665050559557\r",
      " 60 - loss : 169.81464097931314\r",
      " 61 - loss : 169.57378265847137\r",
      " 62 - loss : 169.33406776007374\r",
      " 63 - loss : 169.09548856478335\r",
      " 64 - loss : 168.8580374163452\r",
      " 65 - loss : 168.6217067210133\r",
      " 66 - loss : 168.38648894698377\r",
      " 67 - loss : 168.15237662383328\r",
      " 68 - loss : 167.91936234196248\r",
      " 69 - loss : 167.687438752045\r",
      " 70 - loss : 167.45659856448194\r",
      " 71 - loss : 167.2268345488609\r",
      " 72 - loss : 166.9981395334207\r",
      " 73 - loss : 166.7705064045213\r",
      " 74 - loss : 166.54392810611802\r",
      " 75 - loss : 166.31839763924162\r",
      " 76 - loss : 166.09390806148275\r",
      " 77 - loss : 165.87045248648178\r",
      " 78 - loss : 165.64802408342277\r",
      " 79 - loss : 165.4266160765331\r",
      " 80 - loss : 165.20622174458708\r",
      " 81 - loss : 164.98683442041502\r",
      " 82 - loss : 164.76844749041635\r",
      " 83 - loss : 164.55105439407774\r",
      " 84 - loss : 164.33464862349524\r",
      " 85 - loss : 164.1192237229021\r",
      " 86 - loss : 163.90477328819966\r",
      " 87 - loss : 163.69129096649377\r",
      " 88 - loss : 163.47877045563507\r",
      " 89 - loss : 163.26720550376396\r",
      " 90 - loss : 163.05658990885917\r",
      " 91 - loss : 162.84691751829186\r",
      " 92 - loss : 162.6381822283828\r",
      " 93 - loss : 162.4303779839642\r",
      " 94 - loss : 162.2234987779457\r",
      " 95 - loss : 162.01753865088463\r",
      " 96 - loss : 161.81249169055982\r",
      " 97 - loss : 161.60835203154988\r",
      " 98 - loss : 161.40511385481565\r",
      " 99 - loss : 161.2027713872857\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):    \n",
    "    z = (x.matmul(w) + b)\n",
    "    loss = torch.mean((z - y)**2)  \n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(\"{:3} - loss : {}\".format(epoch, loss.item()), end=\"\\r\")\n",
    "    \n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9dfed43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T07:54:00.112476Z",
     "start_time": "2023-10-14T07:54:00.094487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 집값 : 21.924237389495104 실제 집값 : 18.2\n"
     ]
    }
   ],
   "source": [
    "y_pred = x.matmul(w) + b\n",
    "print(\"예측한 집값 :\", y_pred[19].item(), \"실제 집값 :\", target[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c9497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297ccac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
